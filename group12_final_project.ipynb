{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rgk_Dh7absQU"
      },
      "source": [
        "**In this project, a face recognition and analysis of the results will be performed using the following procedures:**\n",
        "1. face detection\n",
        "2. facial features extraction\n",
        "3. classification\n",
        "4. analysis of the results\n",
        "\n",
        "**The total Project mark is 20. The lab report shall include:**\n",
        "- Description of the implemented project (introduction, procedure and analysis, conclusion) (6 marks).\n",
        "- The project flow block-diagram, illustrations, graphs (such as DET, ROC) and their analysis (6 marks).\n",
        "- Code or any modifications to the code (8 marks)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {},
      "outputs": [],
      "source": [
        "#%pip install opencv-python"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import cv2\n",
        "import skimage\n",
        "import numpy as np\n",
        "from glob import glob\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "from skimage.feature import local_binary_pattern\n",
        "from sklearn.svm import SVC\n",
        "# from sklearn.svm import SVM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#loads images from folder and returns imges and labels\n",
        "#folder - path to folder with images\n",
        "def get_data(folder):\n",
        "    images = []\n",
        "    images_1D = []\n",
        "    labels = []\n",
        "    \n",
        "    # Iterate over each subfolder in the main directory\n",
        "    for subfolder in os.listdir(folder):\n",
        "        if os.path.isdir(os.path.join(folder, subfolder)): \n",
        "            # Iterate over each image in the subfolder\n",
        "            for filename in os.listdir(os.path.join(folder, subfolder)):\n",
        "                path = os.path.join(folder, subfolder, filename)\n",
        "                if os.path.isfile(path):\n",
        "                    #read image\n",
        "                    img = cv2.imread(path, 0)\n",
        "                    #get label\n",
        "                    label = filename[filename.rfind('s') + 1:filename.rfind('\\\\')]\n",
        "                    label = label.split('.')[0]\n",
        "                    if img is not None:\n",
        "                        #base images stored in array\n",
        "                        # for ploting base images\n",
        "                        images.append(img)\n",
        "\n",
        "                        #get 1D image and store to array\n",
        "                        img = cv2.resize(img, (1, (len(img) * len(img[0]))))\n",
        "                        img = np.float32(np.array(img) / 255.0)\n",
        "                        images_1D.append(img)\n",
        "\n",
        "                        #add label to array\n",
        "                        labels.append(int(label))\n",
        "    \n",
        "    return images, np.array(images_1D)[:,:,0], np.array(labels)  # Return images and Labels\n",
        "\n",
        "def get_lbph(images):\n",
        "    lbp_images = []\n",
        "    for image in images:\n",
        "        lbp = local_binary_pattern(image, 12, 3)\n",
        "        lbp_images.append(lbp)\n",
        "    return lbp_images\n",
        "\n",
        "def train_svm(train_path, test_path, C=5.0, gamma=0.001):\n",
        "    train_data, train_label = get_data(train_path)\n",
        "    test_data, test_label = get_data(test_path)\n",
        "    \n",
        "    svm = SVC(C=C, gamma=gamma, probability=True)\n",
        "    svm.fit(train_data, train_label)\n",
        "    \n",
        "    probability_matrix = svm.predict_proba(test_data)\n",
        "    prediction = np.argmax(probability_matrix, 1)\n",
        "    result = prediction == test_label\n",
        "    accuracy = np.sum(result) / len(result)\n",
        "    \n",
        "    print(\"Accuracy:\", accuracy)\n",
        "\n",
        "def plot_images(images, labels, rows, cols):\n",
        "    fig, axes = plt.subplots(rows, cols, figsize=(10, 5))\n",
        "    for i, image in enumerate(images):\n",
        "        axes[i].imshow(image, cmap='gray')  # Specify cmap='gray' to display grayscale images\n",
        "        axes[i].axis('off')\n",
        "    plt.show()\n",
        "\n",
        "images, images_1D, labels = get_data('./ATT_dataset')\n",
        "\n",
        "lbp = get_lbph(images)\n",
        "\n",
        "fig = None\n",
        "axes = None\n",
        "\n",
        "if len(images) > 0:\n",
        "    fig, axes = plt.subplots(1, min(len(images), 6), figsize=(10, 5))\n",
        "    for i, image in enumerate(images[:6]):\n",
        "        axes[i].imshow(image, cmap='gray')  # Specify cmap='gray' to display grayscale images\n",
        "        axes[i].axis('off')\n",
        "    plt.show()\n",
        "else:\n",
        "    print(\"No images found.\")\n",
        "\n",
        "lbp = get_lbph(images)\n",
        "fig, axes = plt.subplots(1, min(len(lbp), 6), figsize=(10, 5))\n",
        "for i, lbp_image in enumerate(lbp[:6]):\n",
        "    axes[i].imshow(lbp_image, cmap='gray')\n",
        "    axes[i].axis('off')\n",
        "plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### This is part 3 of the provided instructions\n",
        "\n",
        "You can implement Face detection in Python language using OpenCV library. The following code load the face image and convert it to gray scale:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#%ls dog_with_headphones.jpg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "iface_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
        "image_path = './dog_with_headphones.jpg'\n",
        "\n",
        "if os.path.exists(image_path):\n",
        "    img = cv2.imread(image_path)\n",
        "    if img is not None:\n",
        "        img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "    else:\n",
        "        print(f\"Image file '{image_path}' is empty.\")\n",
        "else:\n",
        "    print(f\"Image file '{image_path}' does not exist.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Next the Haar-Cascades is used for the face detection:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "face_box = face_cascade.detectMultiScale(img_gray, 1.1, 4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Here, 1.1 is a scale factor, and 4 is the number of neighbours to retain for the rectangular around the face.\n",
        "An alternative approach to the frontal face cascade approach is LPB-based Haar cascades: https://github.com/opencv/opencv/tree/master/data/lbpcascades \n",
        "\n",
        "Two good full-run examples of face detection can be found here: https://www.datacamp.com/community/tutorials/face-detection-python-opencv#face-detection\n",
        "\n",
        "and here: https://scikit-image.org/docs/dev/auto_examples/applications/plot_face_detection.html\n",
        "\n",
        "For a lot of the project, you may want to create your own custom load function. Here is an example:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "from glob import glob\n",
        "# custom load data function to load images and record subject labels\n",
        "def get_data(path):\n",
        "    paths = glob(path, recursive=True)\n",
        "    data = [] #list of images\n",
        "    label = [] #list of labels\n",
        "    for path in paths :\n",
        "        img = cv2.imread(path,0) # read image\n",
        "        subject_label = path[path.rfind('s')+1: path.rfind ('\\\\')] # extract the label\n",
        "        # pre=processing step\n",
        "        # can resize , rescale , normalize\n",
        "        img = cv2.resize(img, (1, len(img)*len(img[0]))) # reshape image to a 1D vector\n",
        "        img = np.float32(np.array(img)/255.0) # normalize to 0=1 value\n",
        "        # can apply LBP , PCA or other forms of feature extraction\n",
        "        # append images and labels\n",
        "        data.append(img)\n",
        "        # decrease all labels by 1 since subject labels start from 1\n",
        "        label.append(int(subject_label)-1)\n",
        "        \n",
        "    # return np.array(data)[:,:,0], np.array(label)\n",
        "    return np.array(data), np.array(label)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "For classification (face recognition) with SVM, you can still use the version implemented in OpenCV; however, you will not get the probability values required to do the analysis required. Check the following link for the documentation and sample code:\n",
        "\n",
        "https://docs.opencv.org/4.x/d0/dcc/tutorial_non_linear_svms.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#ORL dataset contains 40 subjects with 10 images per subject\n",
        "#5 images are used for training and the remaining 5 images are used for testing\n",
        "train_path = r'ORL\\\\Train Data\\\\*\\\\*'\n",
        "test_path = r'ORL\\\\Test Data\\\\*\\\\*'\n",
        "train_data, train_label = get_data(train_path)\n",
        "test_data, test_label = get_data(test_path)\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "import numpy as np\n",
        "train_path = r'ORL\\\\Train Data\\\\*\\\\*'\n",
        "test_path = r'ORL\\\\Test Data\\\\*\\\\*'\n",
        "# customize get data function to include pre=processing methods ( adding PCA or LBP)\n",
        "\n",
        "train_data , train_label = get_data(train_path) # use the previous custom get data function\n",
        "test_data , test_label = get_data(test_path) # use the previous custom get data function\n",
        "# create MLP with 3 layers of perceptrons\n",
        "# first layers has 128 neurons then 64 then another 128\n",
        "# experiment with different layers / neurons\n",
        "# experiment with different learning rate\n",
        "mlp = MLPClassifier(hidden_layer_sizes =(128 ,64 ,128), learning_rate_init = 0.001, random_state =1)\n",
        "mlp.fit(train_data , train_label)\n",
        "# probability matrix NxM where N is number of samples and M is the number of classes\n",
        "probability_matrix = mlp.predict_proba(test_data)\n",
        "# calculate accuracy\n",
        "prediction = np.argmax(probability_matrix,1)\n",
        "result = prediction == test_label\n",
        "accuracy = np.sum(result)/len(result)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### This is part 4.1.3 in their provided example\n",
        "Both classifiers, SVM and MLP, implementation in the Scikit-Learn has similar interface, where we call .fit(...) for training (using the training set) and .predict(...) to test (using the test set only). In the example, we used .predict_proba(...) to get the probability matrix. The matrix can be used to calculate additional metrics and graphs such as the ROC (FPR vs. TPR) or DET (FPR vs. FNR) curves"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import roc_curve , det_curve\n",
        "# false positive rate (FPR)\n",
        "# true positive rate (TPR)\n",
        "# false negative rate (FNR)\n",
        "# 40 subjects by 100 values\n",
        "roc_fpr = np.zeros((40 ,100))\n",
        "roc_tpr = np.zeros((40 ,100))\n",
        "det_fpr = np.zeros((40 ,100))\n",
        "det_fnr = np.zeros((40 ,100))\n",
        "fig,[ax_roc, ax_det] = plt.subplots(1, 2, figsize=(11, 5))\n",
        "# iterate through number of subjects (40)\n",
        "# calculating the ROC and DET curve for each subject\n",
        "for i in range (40):\n",
        "    # find the fpr by tpr values for ROC\n",
        "    fpr, tpr, = roc_curve(test_label[:]==i, probability_matrix[:,i])\n",
        "    # interpolate rates so each curve contains 100 values\n",
        "    roc_fpr [i] = np.linspace (min(fpr),max(fpr),100)    \n",
        "    roc_tpr [i] = np.interp (roc_fpr[i],fpr,tpr)\n",
        "    # find the fpr by fnr values for DET\n",
        "    fpr, fnr, = det_curve(test_label [:]==i, probability_matrix[:,i])\n",
        "    # interpolate rates so each curve contains 100 values\n",
        "    det_fpr [i] = np.linspace(min(fpr),max(fpr),100)\n",
        "    det_fnr [i] = np.interp(det_fpr[i],fpr ,fnr)\n",
        "# average each subject ’s ROC curve to get the average ROC curve of system\n",
        "roc_mid_fpr = np.mean(roc_fpr,0)\n",
        "roc_mid_tpr = np.mean(roc_tpr,0)\n",
        "ax_roc.plot(roc_mid_fpr, roc_mid_tpr)\n",
        "# average each subject ’s DET curve to get the average DET curve of system\n",
        "det_mid_fpr = np.mean(det_fpr ,0)\n",
        "det_mid_fnr = np.mean(det_fnr ,0)\n",
        "ax_det.plot(roc_mid_fpr, roc_mid_tpr)\n",
        "ax_roc.set_xlabel('FPR')\n",
        "ax_roc.set_ylabel('TPR')\n",
        "ax_roc.set_title(\" Receiver Operating Characteristic (ROC) curves \")\n",
        "ax_det.set_xlabel('FPR')\n",
        "ax_det.set_ylabel('FNR')\n",
        "ax_det.set_title(\" Detection Error Tradeoff (DET) curves \")\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
